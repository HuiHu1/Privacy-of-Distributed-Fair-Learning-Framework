# Privacy-of-Distributed-Fair-Learning-Framework

In this project, we focuses on studying the vulnerability of the proposed distributed fair machine learning framework (https://arxiv.org/abs/1909.08081) under inference attacks. 
We design an attack strategy that infers the protected demographics by solving an integer programming problem,
then design two defense strategies at the third party, one is perturbing the true value of covariances and the other is randomizing the selections of fair hypotheses via soft-threshold policy.

Datasets for Fair Machine Learning Research: https://uwyomachinelearning.github.io/. 
